import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

# Load your new dataset
df = pd.read_csv('Month_Value_1.csv')

# Visualize the time series data
plt.figure(figsize=(12, 6))
plt.plot(df['Period'], df['Revenue'], label='Revenue')
plt.title('Revenue Over Time')
plt.xlabel('Period')
plt.ylabel('Revenue')
plt.legend()
plt.show()

# Decompose the time series into trend, seasonality, and residual components
result = seasonal_decompose(df['Revenue'], model='additive', period=1)  # You may need to adjust the period
result.plot()
plt.show()

# Check for stationarity using the Augmented Dickey-Fuller test
adf_result = adfuller(df['Revenue'])
print(f'ADF Statistic: {adf_result[0]}')
print(f'p-value: {adf_result[1]}')
print('Critical Values:')
for key, value in adf_result[4].items():
    print(f'   {key}: {value}')

# Visualize autocorrelation and partial autocorrelation functions
plot_acf(df['Revenue'])
plot_pacf(df['Revenue'])
plt.show()

# Smoothing technique (Example: Rolling Mean)
rolling_mean = df['Revenue'].rolling(window=12).mean()  # Assuming monthly data, you may need to adjust the window
plt.figure(figsize=(12, 6))
plt.plot(df['Period'], df['Revenue'], label='Original Data')
plt.plot(df['Period'], rolling_mean, label='Rolling Mean', color='red')
plt.title('Original Data vs Rolling Mean')
plt.xlabel('Period')
plt.ylabel('Revenue')
plt.legend()
plt.show()

# Create a new dataset for forecasting (Example: Linear Regression)
df['Period'] = pd.to_datetime(df['Period'])  # Convert 'Period' to datetime if not already
df['Months'] = (df['Period'] - df['Period'].min()) / np.timedelta64(1, 'M')  # Using months as a proxy for time
df['Months'] = df['Months'].astype(int)  # Convert to integer
X = df[['Months']].values
y = df['Revenue'].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Train a simple linear regression model
model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
model.fit(X_train, y_train)

# Make predictions
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Visualize the results
plt.figure(figsize=(12, 6))
plt.plot(df['Period'][:-len(X_test)], y_train, label='Training Data')
plt.plot(df['Period'][-len(X_test):], y_test, label='Testing Data')
plt.plot(df['Period'][:-len(X_test)], y_pred_train, label='Training Prediction', linestyle='dashed')
plt.plot(df['Period'][-len(X_test):], y_pred_test, label='Testing Prediction', linestyle='dashed')
plt.title('Linear Regression Forecasting')
plt.xlabel('Period')
plt.ylabel('Revenue')
plt.legend()
plt.show()

# Evaluate the model
mse_train = mean_squared_error(y_train, y_pred_train)
mse_test = mean_squared_error(y_test, y_pred_test)
print(f'Mean Squared Error (Training): {mse_train}')
print(f'Mean Squared Error (Testing): {mse_test}')
